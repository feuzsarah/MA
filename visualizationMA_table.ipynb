{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The idea of the visualization and the base code was taken from https://github.com/AIML-IfI/openset-imagenet-comparison. It was developed **by Palechor, Andres and Bhoumik, Annesha and GÃ¼nther, Manuel** for the paper \"**Large-Scale Open-Set Classification Protocols for ImageNet**\" (Winter Conference on Applications of Computer Vision (WACV)) in 2023. You can find the citation in the readme file.\n",
        "\n",
        "Adaptions have been made to visualize a different version of the table-layout.  "
      ],
      "metadata": {
        "id": "1f0-W1tR-wK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import multiprocessing\n",
        "import collections\n",
        "import subprocess\n",
        "import pathlib\n",
        "import os, sys\n",
        "import torch\n",
        "import numpy\n",
        "\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from matplotlib import pyplot, cm, colors\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from matplotlib.ticker import MaxNLocator, LogLocator\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import ticker\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import LogLocator, NullFormatter\n",
        "from matplotlib import colors\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import yaml\n",
        "\n",
        "THRESHOLDS = {1e-4: \"$10^{-4}$\",\n",
        "              1e-3: \"$10^{-3}$\",\n",
        "              1e-2: \"$10^{-2}$\",\n",
        "              1e-1: \"$10^{-1}$\",\n",
        "              0.2: \"$0.2$\",\n",
        "              1: \"$1$\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# get distinguishable colors\n",
        "import matplotlib.cm\n",
        "colors = matplotlib.cm.tab10(range(10))\n",
        "\n",
        "COLORS = {\n",
        "    \"threshold\": colors[0],\n",
        "    \"openmax\": colors[8],\n",
        "    \"proser\": colors[2],\n",
        "    \"evm\": colors[3],\n",
        "    \"maxlogits\": colors[5]\n",
        "}\n",
        "\n",
        "STYLES = {\n",
        "    \"entropic\": \"dashed\",\n",
        "    \"softmax\": \"solid\",\n",
        "    \"garbage\": \"dotted\",\n",
        "    \"p1\": \"dashed\",\n",
        "    \"p2\": \"dotted\",\n",
        "    \"p3\": \"solid\"\n",
        "}\n",
        "\n",
        "NAMES = {\n",
        "    \"threshold\": \"Threshold\",\n",
        "    \"openmax\": \"OpenMax\",\n",
        "    \"proser\": \"PROSER\",\n",
        "    \"evm\": \"EVM\",\n",
        "    \"maxlogits\": \"MaxLogits\",\n",
        "    \"entropic\": \"EOS\",\n",
        "    \"softmax\": \"Softmax\",\n",
        "    \"garbage\": \"Garbage\",\n",
        "    \"p1\": \"P_1\",\n",
        "    \"p2\": \"P_2\",\n",
        "    \"p3\": \"P_3\",\n",
        "    1: \"$P_1$\",\n",
        "    2: \"$P_2$\",\n",
        "    3: \"$P_3$\"\n",
        "}"
      ],
      "metadata": {
        "id": "OUabx-TN9nv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to load the scores and ground truths\n",
        "def load_scores(use_best, algorithm, loss, protocol ,method, eval, experiment_number):\n",
        "    suffix = \"best\" if use_best else \"curr\"\n",
        "    scores = defaultdict(lambda: defaultdict(dict))\n",
        "    ground_truths = {}\n",
        "    scr = \"scores\"\n",
        "\n",
        "    score_file = f\"{loss}_{algorithm}_{eval}_arr_{suffix}_{str(experiment_number)}.npz\"\n",
        "\n",
        "    if(os.path.exists(score_file)):\n",
        "        results = numpy.load(score_file)\n",
        "        scores[protocol][loss][algorithm] = results[scr]\n",
        "        if(protocol not in ground_truths):\n",
        "            ground_truths[protocol] = results[\"gt\"].astype(int)\n",
        "        else:\n",
        "            assert numpy.all(results[\"gt\"] == ground_truths[protocol])\n",
        "\n",
        "    else:\n",
        "      print(\"did not find the data\")\n",
        "\n",
        "    return scores, ground_truths\n",
        "\n",
        "#function to calculate the CCR at FPR-values\n",
        "def ccr_at_fpr(gt, scores, fpr_values, unk_label=-1):\n",
        "\n",
        "    # compute ccr and fpr values from scores\n",
        "    ccr, fpr = calculate_oscr(gt, scores, unk_label)\n",
        "\n",
        "    ccrs = []\n",
        "    for t in fpr_values:\n",
        "        # get the FPR value that is closest, but above the current threshold\n",
        "        candidates = np.nonzero(np.maximum(t - fpr, 0))[0]\n",
        "        if candidates.size > 0:\n",
        "            ccrs.append(ccr[candidates[0]])\n",
        "        else:\n",
        "            ccrs.append(None)\n",
        "\n",
        "    return ccrs"
      ],
      "metadata": {
        "id": "k0diKjAg-MiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnEztl749mBm"
      },
      "outputs": [],
      "source": [
        "#function to write a table with the CCR at FPR-values\n",
        "def ccr_table_new(protocols,protocols2,protocols3,title_column,title_1, title_2, title_3,algorithm, loss, scores, gt, scores2, gt2, scores3, gt3, output_name, caption):\n",
        "      \"\"\"\n",
        "      Input:\n",
        "\n",
        "        protocols = protocol number of scores, gt\n",
        "        protocols2 = protocol number of scores2, gt2\n",
        "        protocols3 = protocol number of scores3, gt3\n",
        "\n",
        "        output_name = name of the file\n",
        "        caption = define the caption for the table\n",
        "        title_column = the title of the first column which defines the different methods\n",
        "        title_1 to title_3 = title of the tree data inputs (scores,gt), (scores2,gt2),(scores3,gt3)\n",
        "        algorithm = the used algorithm for the method data\n",
        "        loss = the used loss function for the method data\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      #parameter defined\n",
        "      fpr_thresholds = [1e-3,1e-2,1e-1, 1.]\n",
        "      #losses = ('entropic')\n",
        "      #algorithms = ('threshold')\n",
        "\n",
        "      def nonemax(a,b):\n",
        "          b = numpy.array([v if v is not None else numpy.nan for v in b])\n",
        "          return numpy.where(numpy.logical_and(numpy.logical_not(numpy.isnan(b)), b >= a), b, a)\n",
        "\n",
        "      latex_file = f\"{output_name}.tex\"\n",
        "      print(\"Writing CCR tables for protocol\", protocol, \"to file\", latex_file)\n",
        "\n",
        "      # compute all CCR values and store the values for protocol 1\n",
        "      results_n_p1 = collections.defaultdict(dict)\n",
        "      max_total_n_p1 = numpy.zeros(len(fpr_thresholds))\n",
        "      results_u_p1 = collections.defaultdict(dict)\n",
        "      max_total_u_p1 = numpy.zeros(len(fpr_thresholds))\n",
        "\n",
        "      ccrs_p1 = ccr_at_fpr(gt[protocols], scores[protocols][loss][algorithm], fpr_thresholds, unk_label=-1)\n",
        "      results_n_p1[algorithm][loss] = ccrs_p1\n",
        "      max_total_n_p1 = nonemax(max_total_n_p1, ccrs_p1)\n",
        "\n",
        "      ccrs_p1 = ccr_at_fpr(gt[protocols], scores[protocols][loss][algorithm], fpr_thresholds, unk_label=-2)\n",
        "      results_u_p1[algorithm][loss] = ccrs_p1\n",
        "      max_total_u_p1 = nonemax(max_total_u_p1, ccrs_p1)\n",
        "\n",
        "      total_u_p1 = max_total_u_p1\n",
        "      total_u_p1 = np.append(total_u_p1,sum(max_total_u_p1))\n",
        "\n",
        "      total_n_p1 = max_total_n_p1\n",
        "      total_n_p1 = np.append(total_n_p1,sum(max_total_n_p1))\n",
        "\n",
        "\n",
        "      # compute all CCR values and store the values for protocol 2\n",
        "      results_n_p2 = collections.defaultdict(dict)\n",
        "      max_total_n_p2 = numpy.zeros(len(fpr_thresholds))\n",
        "      results_u_p2 = collections.defaultdict(dict)\n",
        "      max_total_u_p2 = numpy.zeros(len(fpr_thresholds))\n",
        "\n",
        "      ccrs_p2 = ccr_at_fpr(gt2[protocols2], scores2[protocols2][loss][algorithm], fpr_thresholds, unk_label=-1)\n",
        "      results_n_p2[algorithm][loss] = ccrs_p2\n",
        "      max_total_n_p2 = nonemax(max_total_n_p2, ccrs_p2)\n",
        "\n",
        "      ccrs_p2 = ccr_at_fpr(gt2[protocols2], scores2[protocols2][loss][algorithm], fpr_thresholds, unk_label=-2)\n",
        "      results_u_p2[algorithm][loss] = ccrs_p2\n",
        "      max_total_u_p2 = nonemax(max_total_u_p2, ccrs_p2)\n",
        "\n",
        "      total_u_p2 = max_total_u_p2\n",
        "      total_u_p2 = np.append(total_u_p2,sum(max_total_u_p2))\n",
        "\n",
        "      total_n_p2 = max_total_n_p2\n",
        "      total_n_p2 = np.append(total_n_p2,sum(max_total_n_p2))\n",
        "\n",
        "\n",
        "      # compute all CCR values and store the values for protocol 3\n",
        "      results_n_p3 = collections.defaultdict(dict)\n",
        "      max_total_n_p3 = numpy.zeros(len(fpr_thresholds))\n",
        "      results_u_p3 = collections.defaultdict(dict)\n",
        "      max_total_u_p3 = numpy.zeros(len(fpr_thresholds))\n",
        "\n",
        "      ccrs_p3 = ccr_at_fpr(gt3[protocols3], scores3[protocols3][loss][algorithm], fpr_thresholds, unk_label=-1)\n",
        "      results_n_p3[algorithm][loss] = ccrs_p3\n",
        "      max_total_n_p3 = nonemax(max_total_n_p3, ccrs_p3)\n",
        "\n",
        "      ccrs_p3 = ccr_at_fpr(gt3[protocols3], scores3[protocols3][loss][algorithm], fpr_thresholds, unk_label=-2)\n",
        "      results_u_p3[algorithm][loss] = ccrs_p3\n",
        "      max_total_u_p3 = nonemax(max_total_u_p3, ccrs_p3)\n",
        "\n",
        "      total_u_p3 = max_total_u_p3\n",
        "      total_u_p3 = np.append(total_u_p3,sum(max_total_u_p3))\n",
        "\n",
        "      total_n_p3 = max_total_n_p3\n",
        "      total_n_p3 = np.append(total_n_p3,sum(max_total_n_p3))\n",
        "\n",
        "      #write latex table to the txt file\n",
        "      with open(latex_file, \"w\") as f:\n",
        "        f.write(\"\\\\begin{table}[H]\\n\")\n",
        "        f.write(\"\\\\centering \\n\")\n",
        "        f.write(\"\\\\begin{tabular}{c |c c c|c c c c | c} \\n\")\n",
        "        f.write(f\"\\\\textbf{{{title_column} }}& \\multicolumn{{3}}{{c|}}{{\\\\textbf{{Negative}}}} & \\multicolumn{{3}}{{c}}{{\\\\textbf{{Unknown}}}}& \\\\textbf{{Acc}} & \\\\textbf{{$\\sum$}}\\\\\\ \\n\")\n",
        "        f.write(\"\\\\rule{0pt}{12pt} \\n\")\n",
        "        f.write(\"\\\\textbf{ }& $10e-3$& $10e-2$& $10e-1$ & $10e-3$& $10e-2$& $10e-1$ & $1.$ & \\\\textbf{ } \\\\\\ \\n\")\n",
        "        f.write(\"\\\\rule{0pt}{12pt} \\n\")\n",
        "        f.write(f\"\\\\textit{{{title_1}}}  & {total_n_p1[0]:.3f} & {total_n_p1[1]:.3f} & {total_n_p1[2]:.3f} & {total_u_p1[0]:.3f}& {total_u_p1[1]:.3f} & {total_u_p1[2]:.3f} & {total_u_p1[3]:.3f}& {total_u_p1[4]:.3f}\\\\\\ \\n\")\n",
        "        f.write(\"\\\\rule{0pt}{8pt} \\n\")\n",
        "        f.write(f\"\\\\textit{{{title_2}}}  & {total_n_p2[0]:.3f} & {total_n_p2[1]:.3f} & {total_n_p2[2]:.3f} & {total_u_p2[0]:.3f}& {total_u_p2[1]:.3f} & {total_u_p2[2]:.3f} & {total_u_p2[3]:.3f}& {total_u_p2[4]:.3f}\\\\\\ \\n\")\n",
        "        f.write(\"\\\\rule{0pt}{8pt} \\n\")\n",
        "        f.write(f\"\\\\textit{{{title_3}}}  & {total_n_p3[0]:.3f} & {total_n_p3[1]:.3f} & {total_n_p3[2]:.3f} & {total_u_p3[0]:.3f}& {total_u_p3[1]:.3f} & {total_u_p3[2]:.3f} & {total_u_p3[3]:.3f}& {total_u_p3[4]:.3f}\\\\\\ \\n\")\n",
        "        f.write(\"\\\\end{tabular} \\n\")\n",
        "        f.write(f\"\\\\caption{{{caption}}}\\n\")\n",
        "        f.write(\"\\\\end{table}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "use_best = False\n",
        "protocols = (2)\n",
        "algorithm = 'threshold'\n",
        "protocol = 2\n",
        "method = 'mixup'\n",
        "loss = 'entropic'\n",
        "\n",
        "#enter the data for the three protocols\n",
        "scores, gt = load_scores(use_best, algorithm, loss,1 ,method,'test', 'p1')\n",
        "scores1, gt1 = load_scores(use_best, algorithm, loss, 2 ,method,'test', 'p2')\n",
        "scores2, gt2 = load_scores(use_best, algorithm, loss, 3 ,method,'test', 'p3')\n",
        "\n",
        "#make the table\n",
        "ccr_table_new(1,2,3,\"Experiments\",\"$P1$ \",\"$P2$\",\"$P3$\", algorithm, loss, scores, gt,scores1, gt1,scores2, gt2, 'Title', 'CCR@FPR for all protocols')\n"
      ],
      "metadata": {
        "id": "nBhPvKcO9uXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
